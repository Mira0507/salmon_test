---
output: html_document
---

```{r global_options, include=FALSE}

knitr::opts_chunk$set(
    warning=FALSE,
    message=FALSE
    )

```

## Loading packages

```{r loading_packages}
library(data.table)
library(rmarkdown)
library(AnnotationHub)
library(tidyverse)
library(tximport)
library(ggplot2)
library(DESeq2)
library(pheatmap)
```

## Setting AnnotationHub

```{r annotationhub_setup}

AnnotationSpecies <- "Homo sapiens"  # Assign your species 
MyCache <- "../rawdata/AnnoCache"
ah <- AnnotationHub(hub=getAnnotationHubOption("URL"))   # Bring annotation DB

```

## Running AnnotationHub Depending on Output of Interest

```{r run_annotationhub}

ahQuery <- query(ah, c("OrgDb", AnnotationSpecies))      # Filter annotation of interest

if (length(ahQuery) == 1) {
    DBName <- names(ahQuery)
} else if (length(ahQuery) > 1) {
               DBName <- names(ahQuery)[1]
} else {
    print("You don't have a valid DB")
    rmarkdown::render() 
} 

AnnoDb <- ah[[DBName]] # Store into an OrgDb object  


# Explore your OrgDb object with following accessors:
# columns(AnnpDb)
# keytypes(AnnoDb)
# keys(AnnoDb, keytype=..)
# select(AnnoDb, keys=.., columns=.., keytype=...)
AnnoKey <- keys(AnnoDb, keytype="ENSEMBLTRANS")

# Note: Annotation has to be done with not genome but transcripts 
AnnoDb <- select(AnnoDb, 
                 AnnoKey,
                 keytype="ENSEMBLTRANS",
                 columns="SYMBOL")

```


## Checking AnnotationHub Output 

```{r checking_annotationhub_output}

# Check if your AnnoDb has been extracted and saved correctely
class(AnnoDb)
head(AnnoDb)

```

## Defining File Name and Path for .sf Files
### .sf files have been created from fastq data by salmon


```{r preparing_importing.sf}

# This code chunk needs to be written by yourself 

# Define sample names 
SampleNames <-  c("Mock_72hpi_S1",
                 "Mock_72hpi_S2",
                 "Mock_72hpi_S3",
                 "SARS-CoV-2_72hpi_S7",
                 "SARS-CoV-2_72hpi_S8",
                 "SARS-CoV-2_72hpi_S9") 


# Define .sf file path
sf <- c(paste0("./", 
               SampleNames,
               ".fastq.gz.salmon_quant/quant.sf"))

# Define sample groups
group <- c(rep("Mock", 3), rep("COVID", 3))

# Create metadata
metadata <- data.frame(Sample=factor(SampleNames, levels=SampleNames),
                       Group=factor(group, levels=c("Mock", "COVID")),
                       Path=sf)

rownames(metadata) <- SampleNames
```

## Extracting TPM Data from .sf files 


```{r saving_tpm_to_dataframe}


TPMTable <- data.frame(Transcript=AnnoDb$ENSEMBLTRANS,
    Gene=AnnoDb$SYMBOL)

# Extract TPM and combine to the TPMTable data frame
 for (x in sf) {
        
        txi <- tximport(x,            # path for a quant.sf file  
                        type="salmon",     
                        tx2gene=AnnoDb,txOut=TRUE)

        tpm <- as.data.frame(txi$abundance) 
         
        tpm <- rownames_to_column(tpm, var = colnames(TPMTable)[1]) 

        TPMTable <- full_join(TPMTable, 
                              tpm, 
                              by=colnames(TPMTable)[1])

 }


# Assign column names to sample names 
colnames(TPMTable)[3:ncol(TPMTable)] <- SampleNames
```

## Data Trimming (NA and zero-TPM transcripts)


```{r treaming_TPMTable}

# Remove NA-containing transcripts
TPMTable <- TPMTable[complete.cases(TPMTable),]


# Remove zero-TPM transcripts 
nonzeroTPM <- rowSums(TPMTable[3:ncol(TPMTable)]) > 0
TPMTable <- TPMTable[nonzeroTPM,]


```

## Exploring Cleaned TPM Data
### Saving as a csv file


```{r exploring_TPMTable}

# Exploratory data analysis
dim(TPMTable)
head(TPMTable)
summary(TPMTable)

# Save the raw tpm table as a csv file
write.csv(TPMTable, "Read_TPM.csv")
```

## Plotting Library Size per Sample


```{r library_size}

# Create a library size table
LibSizeTable <- colSums(TPMTable[3:ncol(TPMTable)], 
                        na.rm=TRUE) 

# Data Cleaning
LibSize <- data.frame(Read=LibSizeTable) %>%
    rownames_to_column(var="Sample") %>%
    inner_join(metadata[, c("Sample", "Group")],
               by="Sample")

# Creat a bar plot presenting library size of the dataset
ggplot(LibSize,
       aes(x=Sample,
           y=Read,
           fill=Group,
           label=round(Read))) +
           geom_bar(stat="identity", width=0.8) +
           ggtitle("Library Size") +
           ylab("Number of Total Transcripts (TPM)") +
           theme_bw() + 
           scale_y_log10() +
           geom_text(vjust=1.5) +
           theme(axis.text.x=element_text(angle=45, 
                                          vjust=0.5))


```

## Plotting Distribution of TPM per Sample


```{r distribution_of_transcripts}

# Data Cleaning
txDistribution <- gather(TPMTable,
                         "Sample",
                         "Read",
                         -c(Transcript,
                            Gene))


# Create a density plot presenting distribution of transcripts
ggplot(txDistribution,
       aes(x=Read,
           color=Sample)) + 
           geom_density(alpha=0.5) + 
           theme_bw() +
           ggtitle("Distribution of Total Transcripts") + 
           xlab("Number of Transcripts (TPM)") +
           ylab("Density") + 
           scale_x_log10()

```

## Cleaning TPM Data for DESeq
### Converting Raw TPM to an integer matrix


```{r deseq_datacleaning}

# Assigne rownames: Transcript_Gene
RowNames <- paste(TPMTable$Transcript, TPMTable$Gene, sep="_")
rownames(TPMTable) <- RowNames

# Build a count matrix without Transcript/Gene
TPMMatrix <- TPMTable[, SampleNames]

# Determine integer range
MaxColumnMean <- max(colMeans(TPMMatrix)) 
logScale <- c(1e6, 1e5, 1e4, 1e3, 1e2, 10, 1) 
MinRange <- 0 
for (x in logScale) {
    num = x - MaxColumnMean
    if (num > 0) {
        MinRange <- x
    }
}
FinalMultiplication <- MinRange * 10


# Convert TPM integer 
TPMMatrix <- as.matrix(TPMMatrix * FinalMultiplication)
TPMMatrix <- round(TPMMatrix)
```

## Creating an DESeq object and VST


```{r creating_DESeqObject}


dds <- DESeqDataSetFromMatrix(TPMMatrix, 
                              colData=metadata,
                              design=~Group)

vsd <- varianceStabilizingTransformation(dds,
                                         blind=TRUE) 




```

## Estimating Size Factors, Dispersions, and Conducting Wald Test


```{r sizefactors}


# Calculate and add size factors to the DEseq object
dds <- estimateSizeFactors(dds)

# Extract and save the size factors as a data frame
sizeFactor <- as.data.frame(round(sizeFactors(dds), 3))
colnames(sizeFactor) <- 'Size_Factor'
sizeFactor <- sizeFactor %>%
    rownames_to_column(var="Sample") %>%
    inner_join(metadata[, 1:ncol(metadata)-1], by="Sample") 

# Create a plot comparing the size factors by sample
ggplot(sizeFactor, aes(x=Sample, 
                       y=Size_Factor, 
                       fill=Group,
                       label=Size_Factor)) +
    geom_bar(stat="identity", width=0.8) +
    theme_bw() + 
    ggtitle("Size Factors") +
    geom_text(vjust=1.5) +
    theme(axis.text.x=element_text(angle=45, 
                                   vjust=0.5)) + 
ylab("Size Factor") 

# Calculate and add dispersions to the DEseq object
dds <- estimateDispersions(dds)

# Add wald test to the DESeq object
dds <- nbinomWaldTest(dds)


```



## Sample QC: Principal Component Analysis

```{r QC_PCA}

# Assigne what to compare
GroupOfInterest <- c("Group")

# Extract PCA eigenvalues 
PCAMatrix <- plotPCA(vsd,
        intgroup=GroupOfInterest,
        returnData=TRUE)  

# Create a PCA plot 
plotPCA(vsd,
        intgroup=GroupOfInterest,
        returnData=FALSE) +
theme_bw() +
ggtitle("PCA")

```

## Sample QC: Sample Clustering Heatmap

```{r QC_heatmap}

# Clean the extracted PCA eigenvalue data 
EigenValues <- as.matrix(PCAMatrix[, c("PC1", "PC2")])

# Setting heatmap metadata for annotation
HeatmapAnno <- PCAMatrix[, GroupOfInterest]
names(HeatmapAnno) <- rownames(PCAMatrix)
HeatmapAnno <- as.data.frame(HeatmapAnno)

# Create a heatmap
pheatmap(EigenValues, 
         annotation_row=HeatmapAnno, main="Sample Clustering Heatmap")


```





```{r DE_analysis}

# Running DESeq 
dds <- DESeq(dds)

# Extracting DE results
res <- results(dds, contrast=c("Group", "COVID", "Mock"))

# Check result names 
resultsNames(dds)


```


```{r}

```


## Session Info 

```{r sessionInfo}
sessionInfo()
```
