---
output: html_document
---

```{r global_options, include=FALSE}

knitr::opts_chunk$set(
    warning=FALSE,
    message=FALSE
    )

```

## Loading packages

```{r loading_packages}
library(data.table)
library(rmarkdown)
library(AnnotationHub)
library(tidyverse)
library(tximport)
library(ggplot2)
library(DESeq2)
library(pheatmap)
```

## Setting AnnotationHub
## Assign your species of interest

```{r annotationhub_setup}

AnnotationSpecies <- "Homo sapiens"  # Assign your species 
ah <- AnnotationHub(hub=getAnnotationHubOption("URL"))   # Bring annotation DB

```

## Running AnnotationHub 

```{r run_annotationhub}

ahQuery <- query(ah, c("OrgDb", AnnotationSpecies))      # Filter annotation of interest

if (length(ahQuery) == 1) {
    DBName <- names(ahQuery)
} else if (length(ahQuery) > 1) {
               DBName <- names(ahQuery)[1]
} else {
    print("You don't have a valid DB")
    rmarkdown::render() 
} 

AnnoDb <- ah[[DBName]] # Store into an OrgDb object  


# Explore your OrgDb object with following accessors:
# columns(AnnpDb)
# keytypes(AnnoDb)
# keys(AnnoDb, keytype=..)
# select(AnnoDb, keys=.., columns=.., keytype=...)
AnnoKey <- keys(AnnoDb, keytype="ENSEMBLTRANS")

# Note: Annotation has to be done with not genome but transcripts 
AnnoDb <- select(AnnoDb, 
                 AnnoKey,
                 keytype="ENSEMBLTRANS",
                 columns="SYMBOL")

```


## Checking out the AnnotationHub output 

```{r checking_annotationhub_output}

# Check if your AnnoDb has been extracted and saved correctely
class(AnnoDb)
head(AnnoDb)

```

## Defining file name and path for .sf files
### .sf files have been created from fastq data by salmon


```{r preparing_importing.sf}

# This code chunk needs to be written by yourself 

# Define sample names 
SampleNames <-  c("Mock_72hpi_S1",
                 "Mock_72hpi_S2",
                 "Mock_72hpi_S3",
                 "SARS-CoV-2_72hpi_S7",
                 "SARS-CoV-2_72hpi_S8",
                 "SARS-CoV-2_72hpi_S9") 

# Define group level
GroupLevel <- c("Mock", "COVID")

# Define contrast for DE analysis
Contrast <- c("Group", "COVID", "Mock")


# Set a directory to save csv files
dir.create("./csv")


# Define .sf file path
sf <- c(paste0(SampleNames,
               ".fastq.gz.salmon_quant/quant.sf"))

# Define sample groups
group <- c(rep("Mock", 3), rep("COVID", 3))

# Create metadata
metadata <- data.frame(Sample=factor(SampleNames, levels=SampleNames),
                       Group=factor(group, levels=GroupLevel),
                       Path=sf)

rownames(metadata) <- SampleNames


# Explore the metadata
print(metadata)
```

## Converting .sf files to txi list 


```{r saving_reads_to_dataframe}

# Assign sample names to the input (.sf) file path
names(sf) <- SampleNames

# Run tximport
# tpm vs original counts
txi_tpm <- tximport(sf, 
                    type="salmon",
                    tx2gene=AnnoDb,
                    countsFromAbundance="lengthScaledTPM", # Extracts TPM 
                    ignoreTxVersion=T) 

txi_counts <- tximport(sf, 
                    type="salmon",
                    tx2gene=AnnoDb,
                    ignoreTxVersion=T) 

```

## Exploring the txi outputs 

```{r txi_outputs}

# tpm 
head(txi_tpm$counts)
dim(txi_tpm$counts)

# counts
head(txi_counts$counts)
dim(txi_counts$counts)

```


## Creating an DESeq object from txi and VST


```{r creating_dds_vsd}

# Set a function creating dds and vsd
dds_vsd_fn <- function(txi) { 

    # Create a DESeq object 
    des <- DESeqDataSetFromTximport(txi, 
                                    colData=metadata,
                                    design=~Group)

    # Create a vsd object 
    ves <- vst(des, blind=T)

    # Output them as a list 
    return(list(dds=des, vsd=ves))
}

TPM <- dds_vsd_fn(txi_tpm)
Counts <- dds_vsd_fn(txi_counts)

```

## Estimating size factors, dispersions, and conducting the Wald Test


```{r DESeq_prep}


# Set a function estimating size factors, dispersions, and perform wald test
DESeqPrep_fn <- function(List) {
    
    List[[1]] <- estimateSizeFactors(List[[1]])
    List[[1]] <- estimateDispersions(List[[1]])
    List[[1]] <- nbinomWaldTest(List[[1]])
   
    return(List)
}

# Update dds with the function
Counts <- DESeqPrep_fn(Counts) 
TPM <- DESeqPrep_fn(TPM)

####################################################################

# Extract and save the size factors as a data frame
sizeFactor <- as.data.frame(round(sizeFactors(dds), 3))
colnames(sizeFactor) <- 'Size_Factor'
sizeFactor <- sizeFactor %>%
    rownames_to_column(var="Sample") %>%
    inner_join(metadata[, 1:ncol(metadata)-1], by="Sample") 

# Create a plot comparing the size factors by sample
SizeFactorPlot <- 
    ggplot(sizeFactor, aes(x=Sample, 
                       y=Size_Factor, 
                       fill=Group,
                       label=Size_Factor)) +
    geom_bar(stat="identity", width=0.8) +
    theme_bw() + 
    ggtitle("Size Factors") +
    geom_text(vjust=1.5) +
    theme(axis.text.x=element_text(angle=45, 
                                   vjust=0.5)) + 
ylab("Size Factor")

# Print the plot 
print(SizeFactorPlot)


# Extract sizefactor-normalized counts
normCounts <- counts(dds, normalized=TRUE)
head(normCounts)

# Calculate and add dispersions to the DEseq object
dds <- estimateDispersions(dds)

# Add wald test to the DESeq object
dds <- nbinomWaldTest(dds)

```



## Sample QC: Principal Component Analysis

```{r QC_PCA}

# Assigne what to compare
GroupOfInterest <- Contrast[1] 

# Extract PCA eigenvalues 
PCAMatrix <- plotPCA(vsd,
        intgroup=GroupOfInterest,
        returnData=TRUE)  

# Create a PCA plot 
QCPCAPlot<- 
    plotPCA(vsd,
        intgroup=GroupOfInterest,
        returnData=FALSE) +
theme_bw() +
ggtitle("PCA")

# Print the plot
print(QCPCAPlot)


```

## Sample QC: Sample Clustering Heatmap

```{r QC_heatmap}

# Clean the extracted PCA eigenvalue data 
EigenValues <- as.matrix(PCAMatrix[, c("PC1", "PC2")])

# Setting heatmap metadata for annotation
HeatmapAnno <- PCAMatrix[, GroupOfInterest]
names(HeatmapAnno) <- rownames(PCAMatrix)
HeatmapAnno <- as.data.frame(HeatmapAnno)

# Create a heatmap
pheatmap(EigenValues, 
         annotation_row=HeatmapAnno, 
         main="Sample Clustering Heatmap")


```


## Sample QC: Sample Correlation Heatmap


```{r QC_correlation_heatmap}

# Extract a normalized count matrix
vsdMatrix <- assay(vsd)

corMatrix <- cor(vsdMatrix)

pheatmap(corMatrix,
         annotation=HeatmapAnno,
         main="Sample Correlation Heatmap")

```

## Running DE analysis


```{r DE_analysis}

# Run DESeq 
dds <- DESeq(dds)


# Check result names 
ResNames <- resultsNames(dds)
print(ResNames)

```

## Creating a dispersion plot

```{r dispersion_plot}

plotDispEsts(dds)


```

## Setting how to extract fold-change results
### Change variables below

```{r setting_resultcondition}


# Set the threshold of FDR as a variable "alpha" 
alpha=0.1

# Set the coefficients to compare 
Coef <- ResNames[-1]
print(Coef) 


# Set a function to clean result table 
LFCTable_fn <- function(df) {

    df <- df %>% 
        rownames_to_column(var="Annotation") %>%
        separate("Annotation", c("Transcript", "Gene")) %>%
        mutate(FDR=ifelse(padj < 0.1 & !is.na(padj), 
                                   "< 0.1", 
                                   "> 0.1")) 

    return(df)
}
```

## Extracting log2FoldChanges
### You can change alpha depending on your interest of FDR level



```{r DEresult_extraction}

# Extract DE results
# The Contrast variable was defined in the preparing_importing.sf chunk



# Extraction with no shrinkage
# alpha: FDR threshold
Res <- results(dds, contrast=Contrast, alpha=alpha)

# Convert the LFC data to a data frame
ResDF <- LFCTable_fn(as.data.frame(Res))


# Save the LFC data 
write.csv(ResDF, "./csv/Read_LFC_noshrinkage.csv")

# Extracttion without shrinkage in a list 
# name has to be determined in the previous chunk
resList <- list()

for (i in 1:length(Coef)) {

    myresult <- lfcShrink(dds,
                          coef=Coef[i],
                          type="apeglm")
    resList[i] <- myresult
}



```

## Determining what comparison to explore 
### Checkout resList in the previous chunk and save it to a data frame 


```{r LFC_to_dataframe}

# Save data of interest as a data frame for further analysis 
shRes <- as.data.frame(resList[[1]])

# Clean the LFC table 
shRes <- LFCTable_fn(shRes)

# Save the LFC table
write.csv(shRes, "./csv/Read_LFC_shrinkage.csv")

head(shRes)
```

## Exploring distribution of false discovery rate (FDR)

```{r FDR_distribution}

# Create a plot presenting distribution of FDR
FDR_distPlot <- 
    ggplot(shRes,
           aes(x=padj)) + 
geom_density() + 
theme_bw() +
ggtitle("Distribution of False Discovery Rate (FDR)") + 
xlab("Adjusted P-Value") + 
ylab("Density") + 
geom_vline(xintercept=alpha, color="red")

# Print the plot
print(FDR_distPlot)


```

## Exploring FDR statistics

### - NumOfTx: total number of transcripts
### - BelowAlpha: number of transcripts whose FDR is below 0.1
### - NumofNAInFDR: number of transcripts whose FDR is NA
### - PropOfAboveAlpha: BelowAlpha/NumOfTx 


```{r FDR_statistics}

FDR_stat <- data.frame(NumOfTx=nrow(shRes),
                       BelowAlpha=sum(shRes$FDR == "< 0.1"),
                       NumOfNAInFDR=sum(is.na(shRes$padj)), 
                       PropOfAboveAlpha=sum(shRes$FDR == "< 0.1") / nrow(shRes))

head(FDR_stat)
```

## Exploring distribution of log2FoldChange

### Black: total transcripts (padj =/= NA)
### Colored: transcripts above or below FDR=0.1


```{r L2FC_distribution}

# Subset transcripts whose padj are not NA
shRes_nonNa <- subset(shRes, !is.na(padj))


L2FC_dist <- 
    ggplot(shRes_nonNa,
           aes(x=log2FoldChange)) + 
geom_density(color="black") + 
geom_density(data=shRes_nonNa,
             aes(x=log2FoldChange,
                 color=FDR)) +
theme_bw() +
ggtitle("Distribution of Fold Change Values") + 
ylab("Density")

print(L2FC_dist)

```



## Exploring mean-difference with an MA plot


```{r MAplot}


# Define a function creating an MA plot
MA_fn <- function(df, tit) {

    ggplot(df, 
           aes(x=baseMean,
               y=log2FoldChange,
               color=FDR)) +
geom_point()+ 
scale_x_log10() + 
theme_bw() + 
scale_color_manual(values=c("blue", "grey")) + 
ggtitle(tit)
}


# Create MA plots with or without shrinkage
MAplot_noshr <- MA_fn(ResDF, "Mean-Differene without shrinkage")
MAplot_shr <- MA_fn(shRes, "Mean-Difference with shrinkage")

# Print the plots
print(MAplot_noshr)
print(MAplot_shr)

```

## Volcano plot

```{r volcano_plot}


ggplot(shRes, 
       aes(x=log2FoldChange,
           y= -log10(padj),
           color=FDR)) + 
geom_point() +
theme_bw() +
scale_color_manual(values=c("blue", "grey")) + 
ggtitle("Volcano Plot") + 
ylab("-log10(FDR)")

```

## Exploring transcription profiling (FDR < 0.1)


```{r transcription_profiling_FDR}

# Determine row numbers whose FDR is below alpha 
RowBelowAlpha <- which(shRes$FDR == "< 0.1")

# Subset normalized transcript counts with FDR below alpha 
TranscriptsBelowAlpha <- assay(vsd)[RowBelowAlpha,]

# Create a heatmap from TranscriptsBelowAlpha 
pheatmap(TranscriptsBelowAlpha,
         annotation=HeatmapAnno,
         main="Transcription Profiles (FDR < 0.1)")

```

## Exploring transcription profiling 
## (FDR < 0.1 & log2FoldChange >= 1)


```{r transciption_profiling_FDRandFold}

# Set minimum log2FoldChange of your interest: MinL2F
MinL2F <- 1

# Determine row numbers whose log2FoldChange >= MinL2F
AboveMinL2F <- which(shRes$FDR == "< 0.1" &
                      shRes$log2FoldChange >= MinL2F)


# Subset normalized transcript counts with log2FoldChange above MinL2F 
TranscriptsAboveMinL2F <- assay(vsd)[AboveMinL2F,]


pheatmap(TranscriptsAboveMinL2F,
         annotation=HeatmapAnno,
         main="Transcription Profiles (FDR < 0.1 and log2FoldChange >= 1)",fontsize_row=5)

length(AboveMinL2F)

```



## Session Info 

```{r sessionInfo}
sessionInfo()
```
